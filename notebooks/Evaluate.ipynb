{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0e5eaa-4b6e-4d4f-98bb-2df783b72394",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede79524-b7d3-4176-ae37-8f83b4f956af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from TumorDetection.data.loader import DataPathLoader\n",
    "from TumorDetection.data.dataset import TorchDataset, Dataset\n",
    "from TumorDetection.utils.dict_classes import DataPathDir, Device, ReportingPathDir, Verbosity\n",
    "from TumorDetection.models.efsnet import EFSNet\n",
    "from TumorDetection.models.utils.lightning_model import LightningModel\n",
    "from TumorDetection.models.utils.trainer import Trainer\n",
    "from TumorDetection.models.utils.load import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8345d8-84b1-4dc6-964f-23bf4c57acf2",
   "metadata": {},
   "source": [
    "## Configuration Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5d21ed-f3e0-4f09-8e3d-6ff38cd4dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'EFSNet_clf_seg'\n",
    "DESCRIPTION = 'EFSNet with classification and binary segmentation.'\n",
    "CLASS_WEIGHTS = [1., 3., 3.]\n",
    "POS_WEIGHT = 5\n",
    "FROM_CHECKPOINT = False\n",
    "VALIDATE = True\n",
    "TEST = True\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = Verbosity.get('verbose')\n",
    "DEVICE = Device.get('device')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba3999-173a-4f81-9508-1c7090d764a4",
   "metadata": {},
   "source": [
    "## Path Finder\n",
    "\n",
    "If not using DataPathLoader (*for BUSI Dataset*) consider passing paths as tuple of:  \n",
    "- Image path\n",
    "- List images masks paths associated\n",
    "- List of associated label mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a73e3a-0679-4328-9c5a-21890199c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPathLoader(DataPathDir.get('dir_path'))\n",
    "paths = dp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97175367-ba48-425a-a110-2dbc657a0b50",
   "metadata": {},
   "source": [
    "## Train Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33419ab5-9b41-4601-b7db-27f0df0a24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_paths, val_paths = train_test_split(paths, test_size=100, random_state=0, shuffle=True)\n",
    "tr_td = TorchDataset(tr_paths,\n",
    "                     crop_prob=None, rotation_degrees=None, \n",
    "                     range_brightness=None, range_contrast=None,range_saturation=None,\n",
    "                     horizontal_flip_prob=None, vertical_flip_prob=None)\n",
    "val_td = TorchDataset(val_paths,\n",
    "                      crop_prob=None, rotation_degrees=None, \n",
    "                     range_brightness=None, range_contrast=None,range_saturation=None,\n",
    "                     horizontal_flip_prob=None, vertical_flip_prob=None)\n",
    "\n",
    "train_data = DataLoader(tr_td,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        drop_last=True,\n",
    "                        shuffle=False)\n",
    "\n",
    "val_data = DataLoader(val_td,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      drop_last=True,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327defd-402f-4d70-a7ab-08fa19c66552",
   "metadata": {},
   "source": [
    "## Model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fed9418-2601-40c5-9502-a1999bf15d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================================================================================\n",
      "Layer (type (var_name))                                           Input Shape               Output Shape              Param #                   Param %\n",
      "=====================================================================================================================================================================\n",
      "LightningModel (LightningModel)                                   [1, 1, 256, 256]          [1, 1, 256, 256]          --                             --\n",
      "├─EFSNet (model)                                                  [1, 1, 256, 256]          [1, 1, 256, 256]          --                             --\n",
      "│    └─Encoder (encoder)                                          [1, 1, 256, 256]          [1, 64, 64, 64]           --                             --\n",
      "│    │    └─InitialBlock (initial_block)                          [1, 1, 256, 256]          [1, 16, 128, 128]         166                         0.09%\n",
      "│    │    └─DownsamplingBlock (downsampling_block1)               [1, 16, 128, 128]         [1, 64, 64, 64]           5,732                       3.04%\n",
      "│    │    └─Sequential (factorized_blocks)                        [1, 64, 64, 64]           [1, 64, 64, 64]           15,248                      8.09%\n",
      "│    │    └─DownsamplingBlock (downsampling_block2)               [1, 64, 64, 64]           [1, 128, 32, 32]          30,468                     16.16%\n",
      "│    │    └─Sequential (super_sdc_blocks)                         [1, 128, 32, 32]          [1, 128, 32, 32]          109,592                    58.14%\n",
      "│    └─Decoder (decoder)                                          [1, 64, 64, 64]           [1, 16, 128, 128]         --                             --\n",
      "│    │    └─UpsamplingBlock (upsample_module1)                    [1, 128, 32, 32]          [1, 64, 64, 64]           12,548                      6.66%\n",
      "│    │    └─Sequential (shufflenet1)                              [1, 64, 64, 64]           [1, 64, 64, 64]           4,258                       2.26%\n",
      "│    │    └─UpsamplingBlock (upsample_module2)                    [1, 64, 64, 64]           [1, 16, 128, 128]         1,348                       0.72%\n",
      "│    │    └─Sequential (shufflenet2)                              [1, 16, 128, 128]         [1, 16, 128, 128]         458                         0.24%\n",
      "│    └─DownsamplingBlock (label_ds)                               [1, 128, 32, 32]          [1, 8, 16, 16]            --                             --\n",
      "│    │    └─MaxPool2d (mxp11)                                     [1, 128, 32, 32]          [1, 128, 16, 16]          --                             --\n",
      "│    │    └─BatchNorm2d (bn11)                                    [1, 128, 16, 16]          [1, 128, 16, 16]          256                         0.14%\n",
      "│    │    └─ConvBlock (cb11)                                      [1, 128, 16, 16]          [1, 8, 16, 16]            1,040                       0.55%\n",
      "│    │    └─ConvBlock (cb21)                                      [1, 128, 32, 32]          [1, 2, 16, 16]            1,029                       0.55%\n",
      "│    │    └─ConvBlock (cb22)                                      [1, 2, 16, 16]            [1, 2, 16, 16]            41                          0.02%\n",
      "│    │    └─ConvBlock (cb23)                                      [1, 2, 16, 16]            [1, 8, 16, 16]            33                          0.02%\n",
      "│    │    └─Dropout2d (spr21)                                     [1, 8, 16, 16]            [1, 8, 16, 16]            --                             --\n",
      "│    │    └─PReLU (act_f)                                         [1, 8, 16, 16]            [1, 8, 16, 16]            1                           0.00%\n",
      "│    └─Flatten (label_fl)                                         [1, 8, 16, 16]            [1, 2048]                 --                             --\n",
      "│    └─Linear (labeler)                                           [1, 2048]                 [1, 3]                    6,147                       3.26%\n",
      "│    └─ConvTranspose2d (segment)                                  [1, 16, 128, 128]         [1, 1, 256, 256]          145                         0.08%\n",
      "=====================================================================================================================================================================\n",
      "Total params: 188,510\n",
      "Trainable params: 188,510\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 287.78\n",
      "=====================================================================================================================================================================\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 178.77\n",
      "Params size (MB): 0.75\n",
      "Estimated Total Size (MB): 179.79\n",
      "=====================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lightningmodel = LightningModel(model=EFSNet(device=DEVICE,\n",
    "                                            verbose=VERBOSE),\n",
    "                                model_name=MODEL_NAME,\n",
    "                                description=DESCRIPTION,\n",
    "                                class_weights=CLASS_WEIGHTS,\n",
    "                                pos_weight=POS_WEIGHT,\n",
    "                                device=DEVICE)\n",
    "lightningmodel = load_model(directory=os.path.join(ReportingPathDir.get('dir_path'), 'ckpt'),\n",
    "                            model_name=MODEL_NAME,\n",
    "                            lightningmodel=lightningmodel)\n",
    "print(summary(lightningmodel, lightningmodel.model.input_shape, \n",
    "              batch_dim=0,\n",
    "              col_names=(\"input_size\", \"output_size\", \"num_params\", \"params_percent\"),\n",
    "              depth=3,\n",
    "              row_settings=[\"var_names\"],\n",
    "        device=lightningmodel.device,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076c99b-b545-4cea-82e0-4c7db2de583f",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1238b7cb-5a0c-47e0-a34d-faf16a846b03",
   "metadata": {},
   "source": [
    "### 1. Training first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b547d77d-cae6-49e1-bfd2-dc591af919a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_data))\n",
    "y_pred = lightningmodel.predict_step(batch, batch_idx=torch.tensor(0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d829270-182e-4d7c-a74b-5f7e2fa8a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "seglab, seg, lab = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e148bbc1-c653-4610-b1b9-70c95fd1d0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 256, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seglab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36fc4c42-4a74-4c0b-b22c-8380b71f7114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa3a3a6d-749c-4174-a343-88c8a3e537ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a88d954b-4c04-4e71-9eb6-e739982a8059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0099)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(seg*lab[:,None,None,None]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e45e7-843d-4369-9acb-1bf80ac03076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604dee8b-7d05-4407-9aab-8eaf6de15163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
