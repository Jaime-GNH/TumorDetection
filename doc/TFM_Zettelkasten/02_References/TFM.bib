@article{al-dhabyaniDatasetBreastUltrasound2020,
  title = {Dataset of Breast Ultrasound Images},
  author = {Al-Dhabyani, Walid and Gomaa, Mohammed and Khaled, Hussien and Fahmy, Aly},
  date = {2020-02},
  journaltitle = {Data in Brief},
  shortjournal = {Data Brief},
  volume = {28},
  eprint = {31867417},
  eprinttype = {pmid},
  pages = {104863},
  issn = {2352-3409},
  doi = {10.1016/j.dib.2019.104863},
  abstract = {Breast cancer is one of the most common causes of death among women worldwide. Early detection helps in reducing the number of early deaths. The data presented in this article reviews the~medical images of breast cancer using ultrasound scan. Breast Ultrasound Dataset is categorized into three classes: normal, benign, and malignant images. Breast ultrasound images can produce great results in classification, detection, and segmentation of breast cancer when combined with machine learning.},
  langid = {english},
  pmcid = {PMC6906728},
  keywords = {Breast cancer,Classification,Dataset,Deep learning,Detection,Medical images,Segmentation,Ultrasound}
}

@article{buenestadocortesAprendizajeFederadoAplicado2022,
  title = {Aprendizaje federado aplicado al diagnóstico de tumores mamarios en imágenes de ultrasonido},
  author = {Buenestado Cortés, Miguel},
  date = {2022-02-01},
  publisher = {{Universidad Nacional de Educación a Distancia (España). Escuela Técnica Superior de Ingeniería Informática. Departamento de Inteligencia Artificial}},
  url = {http://e-spacio.uned.es/fez/view/bibliuned:master-ETSInformatica-ICD-Mbuenestado},
  urldate = {2022-11-20},
  abstract = {En el campo de la medicina, el aprendizaje automático se erige como una herramienta poderosa y eficaz en la automatización de la tarea del diagnóstico por imagen, mediante la creación de modelos informáticos predictivos. Para lograr resultados con un alto grado de fiabilidad, dichos modelos requieren de grandes volúmenes de datos para su aprendizaje, característica poco frecuente en contextos reales, pues organismos e instituciones médicas, individualmente, no suelen disponer de tales cantidades de información. Idealmente, ésta podría ser compartida y cedida mutuamente en busca de un fin común, pero esto resulta altamente improbable, dadas las regulaciones imperantes en la actualidad en torno a la propiedad intelectual y la privacidad de datos médicos de pacientes. A fin de superar tales escollos, surge el paradigma del aprendizaje federado (federated learning). En este Trabajo Fin de Master, aplicamos dicho paradigma en un caso de aplicación concreto (detección de tumores mamarios en imágenes de ultrasonidos), empleando tecnología y técnicas específicas de federación (la librería TensorFlow Federated; la agregación federada estándar, Federated Average, y variantes de la misma), con las que entrenamos modelos predictivos sobre diferentes combinaciones de datasets. Evaluaremos la idoneidad y eficacia de dichos modelos federados, tanto por sí mismos como en comparación con resultados análogos derivados de un aprendizaje clásico. Exponemos que el aprendizaje federado puede alcanzar, bajo ciertas configuraciones, cotas de eficacia similares a las de un aprendizaje clásico. El presente documento se articula, primero, con la introducción de los conceptos clave tocantes al propio caso de estudio: el problema a resolver en cuestión (segmentación de imágenes de ultrasonido), los aspectos concretos del aprendizaje automático que han ayudado a resolverlo (modelo de aprendizaje profundo, una red neuronal convolutiva U-Net) y profundizaremos en los fundamentos del paradigma de aprendizaje federado. Posteriormente, se detallará la metodología aplicada durante el desarrollo del proyecto y se expondrán los resultados derivados del mismo. Finalmente, abordaremos las conclusiones de dichos resultados, así como las limitaciones y posibles mejoras en el ámbito del presente trabajo y del aprendizaje federado, en particular.},
  langid = {spanish},
  file = {C:\Users\Jaime\Zotero\storage\NRV936GH\bibliunedmaster-ETSInformatica-ICD-Mbuenestado.html}
}

@article{duqueasensEnhancedPreprocessingAdaptive2020,
  title = {Enhanced Preprocessing and Adaptive Weighted Loss Function for Improved for White Matter Hyperintensity Segmentation with Convolutional Neural Networks.},
  author = {Duque Asens, Pablo},
  date = {2020-10-06},
  publisher = {{Universidad Nacional de Educación a Distancia (España). Escuela Técnica Superior de Ingeniería Informática. Departamento de Inteligencia Artificial.}},
  url = {http://e-spacio.uned.es/fez/view/bibliuned:master-ETSInformatica-IAA-Pduque},
  urldate = {2022-11-20},
  abstract = {There is a great interest in automating White Matter Hyperintensities (WMH) segmentation due to their importance in the medical eld as well as the great amount of inter- and intra-observer variability that appears when it is manually segmented in magnetic resonance imaging. In this work we present a multistep tailored preprocessing consisting mainly of brain extraction, intensity contrast enhancement, subject based slice cropping and intensity standardization. The segmentation task is then performed by a fully convolutional neural network with attention gates which employs a customized loss function based on the dice similarity coecient and the F1 score. Experimental results on the white matter hyperintensities segmentation challenge [Kuijf et al., 2019] show that our proposed preprocessing improves segmentation, that attention gated U-Net further improves segmentation tasks compared to the original U-Net and our proposed loss function has the potential to improve lesion-wise F1 on DSC based segmentations.},
  langid = {english},
  file = {C:\Users\Jaime\Zotero\storage\UB7CCC48\bibliunedmaster-ETSInformatica-IAA-Pduque.html}
}

@inproceedings{duqueDataPreprocessingAutomatic2019,
  title = {Data {{Preprocessing}} for {{Automatic WMH Segmentation}} with {{FCNNs}}},
  booktitle = {From {{Bioinspired Systems}} and {{Biomedical Applications}} to {{Machine Learning}}},
  author = {Duque, P. and Cuadra, J. M. and Jiménez, E. and Rincón-Zamorano, Mariano},
  editor = {Ferrández Vicente, José Manuel and Álvarez-Sánchez, José Ramón and family=Paz López, given=Félix, prefix=de la, useprefix=true and Toledo Moreo, Javier and Adeli, Hojjat},
  date = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {452--460},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-19651-6_44},
  abstract = {Automatic segmentation of brain white matter hyperintensities (WMH) is a challenging problem. Recently, the proposals based on Fully Convolutional Neural Networks (FCNN) are giving very good results, as it is demostrated by the top WMH challenge architectures. However, the problem is non completely solved yet. In this paper we analyze the influence of preprocessing stages of the input data on a fully convolutional network (FCNN) based on the U-NET architecture. Results demostrate that standarization, skull stripping and contrast enhancement significantly influence the results of segmentation.},
  isbn = {978-3-030-19651-6},
  langid = {english},
  keywords = {Contrast enhancement,Fully Convolutional Neural Networks,Normalization,Standardization,U-NET,White matter hyperintensities}
}

@inproceedings{gamazoEfficientRotationInvariant2022,
  title = {An {{Efficient}} and~{{Rotation Invariant Fourier-Based Metric}} for~{{Assessing}} the~{{Quality}} of~{{Images Created}} by~{{Generative Models}}},
  booktitle = {Bio-Inspired {{Systems}} and {{Applications}}: From {{Robotics}} to {{Ambient Intelligence}}},
  author = {Gamazo, J. and Cuadra, J. M. and Rincón, M.},
  editor = {Ferrández Vicente, José Manuel and Álvarez-Sánchez, José Ramón and family=Paz López, given=Félix, prefix=de la, useprefix=true and Adeli, Hojjat},
  date = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {413--422},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-031-06527-9_41},
  abstract = {Recent progress in generative image modeling is leading to a new era of high-resolution fakes visually indistinguishable from real life images. However, the development of metrics capable of discerning whether images are synthetic or not runs behind the race of achieving the best generator, thus bringing potential threats. We propose a rotation invariant metric capable of distinguishing real and generated image datasets and we call it CSD (Circular Spectrum Distance) due to its circular nature and its inherent relation to the Fourier Spectrum. Its performance is analysed on a whole brain MRI dataset. CSD has similar behavior to FID during training but requires smaller batch sizes and is faster to compute.},
  isbn = {978-3-031-06527-9},
  langid = {english}
}

@online{leDeepReinforcementLearning2021,
  title = {Deep {{Reinforcement Learning}} in {{Computer Vision}}: {{A Comprehensive Survey}}},
  shorttitle = {Deep {{Reinforcement Learning}} in {{Computer Vision}}},
  author = {Le, Ngan and Rathour, Vidhiwar Singh and Yamazaki, Kashu and Luu, Khoa and Savvides, Marios},
  date = {2021-08-25},
  eprint = {2108.11510},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2108.11510},
  urldate = {2023-10-08},
  abstract = {Deep reinforcement learning augments the reinforcement learning framework and utilizes the powerful representation of deep neural networks. Recent works have demonstrated the remarkable successes of deep reinforcement learning in various domains including finance, medicine, healthcare, video games, robotics, and computer vision. In this work, we provide a detailed review of recent and state-of-the-art research advances of deep reinforcement learning in computer vision. We start with comprehending the theories of deep learning, reinforcement learning, and deep reinforcement learning. We then propose a categorization of deep reinforcement learning methodologies and discuss their advantages and limitations. In particular, we divide deep reinforcement learning into seven main categories according to their applications in computer vision, i.e. (i)landmark localization (ii) object detection; (iii) object tracking; (iv) registration on both 2D image and 3D image volumetric data (v) image segmentation; (vi) videos analysis; and (vii) other applications. Each of these categories is further analyzed with reinforcement learning techniques, network design, and performance. Moreover, we provide a comprehensive analysis of the existing publicly available datasets and examine source code availability. Finally, we present some open issues and discuss future research directions on deep reinforcement learning in computer vision},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\Jaime\Zotero\storage\S64JP3E5\2108.html}
}

@article{rinconImprovedAutomaticSegmentation2017,
  title = {Improved {{Automatic Segmentation}} of {{White Matter Hyperintensities}} in {{MRI Based}} on {{Multilevel Lesion Features}}},
  author = {Rincón, M. and Díaz-López, E. and Selnes, P. and Vegge, K. and Altmann, M. and Fladby, T. and Bjørnerud, A.},
  date = {2017-07},
  journaltitle = {Neuroinformatics},
  shortjournal = {Neuroinformatics},
  volume = {15},
  number = {3},
  eprint = {28378263},
  eprinttype = {pmid},
  pages = {231--245},
  issn = {1559-0089},
  doi = {10.1007/s12021-017-9328-y},
  abstract = {Brain white matter hyperintensities (WMHs) are linked to increased risk of cerebrovascular and neurodegenerative diseases among the elderly. Consequently, detection and characterization of WMHs are of significant clinical importance. We propose a novel approach for WMH segmentation from multi-contrast MRI where both voxel-based and lesion-based information are used to improve overall performance in both volume-oriented and object-oriented metrics. Our segmentation method (AMOS-2D) consists of four stages following a "generate-and-test" approach: pre-processing, Gaussian white matter (WM) modelling, hierarchical multi-threshold WMH segmentation and object-based WMH filtering using support vector machines. Data from 28 subjects was used in this study covering a wide range of lesion loads. Volumetric T1-weighted images and 2D fluid attenuated inversion recovery (FLAIR) images were used as basis for the WM model and lesion masks defined manually in each subject by experts were used for training and evaluating the proposed method. The method obtained an average agreement (in terms of the Dice similarity coefficient, DSC) with experts equivalent to inter-expert agreement both in terms of WMH number (DSC~=~0.637 vs. 0.651) and volume (DSC~=~0.743 vs. 0.781). It allowed higher accuracy in detecting WMH compared to alternative methods tested and was further found to be insensitive to WMH lesion burden. Good agreement with expert annotations combined with stable performance largely independent of lesion burden suggests that AMOS-2D will be a valuable tool for fully automated WMH segmentation in patients with cerebrovascular and neurodegenerative pathologies.},
  langid = {english},
  keywords = {Adult,Aged,Algorithms,Amorphous object segmentation,Automated WMH detection,Brain Infarction,Cognitive Dysfunction,Female,Humans,{Image Interpretation, Computer-Assisted},Magnetic Resonance Imaging,Male,Middle Aged,{Nerve Fibers, Myelinated},Object-oriented analysis,Similarity index,White Matter,White matter hyperintensities,White matter lesions,WM modelling}
}

@article{tejeroDetectingOverfittingGANs2020,
  title = {Detecting Overfitting in {{GANs}} with a Metric Based on the {{Fourier}} Spectrum},
  author = {Tejero, Gamazo and Javier, Ángel},
  date = {2020-09-28},
  publisher = {{Universidad Nacional de Educación a Distancia (España). Escuela Técnica Superior de Ingeniería Informática. Departamento de Inteligencia Artificial}},
  url = {http://e-spacio.uned.es/fez/view/bibliuned:master-ETSInformatica-IAA-Ajgamazo},
  urldate = {2022-11-20},
  abstract = {Recent progress in generative image modeling is leading to a new era of highresolution fakes visually indistinguishable from real life images. However, the development of metrics capable of discerning whether images are synthetic or not runs behind the race of achieving the best generator, thus bringing potential threats. We propose a rotation invariant metric capable of distinguishing real and generated images and prove its performance and correlation with subjective evaluation on a brain MRI dataset to generate synthetic white matter lesion images. We name this metric CSD (Circular Spectrum Distance) due to its circular nature and its inherent relation to the Fourier Spectrum. We find that this metric, as opposed to Frechet Inception Distance or Inception Score, detects overfitting during training in terms of generator memorisation without making use of any pretrained network. The conclusions are generalized to CelebA-HQ as a benchmark dataset.},
  langid = {english},
  file = {C:\Users\Jaime\Zotero\storage\NFZE5ZM5\bibliunedmaster-ETSInformatica-IAA-Ajgamazo.html}
}

@article{tianMultistepMedicalImage2020,
  title = {Multi-Step Medical Image Segmentation Based on Reinforcement Learning},
  author = {Tian, Zhiqiang and Si, Xiangyu and Zheng, Yaoyue and Chen, Zhang and Xiaojian, Li},
  date = {2020-03-27},
  journaltitle = {Journal of Ambient Intelligence and Humanized Computing},
  shortjournal = {Journal of Ambient Intelligence and Humanized Computing},
  volume = {13},
  doi = {10.1007/s12652-020-01905-3},
  abstract = {Image segmentation technology has made a remarkable effect in medical image analysis and processing, which is used to help physicians get a more accurate diagnosis. Manual segmentation of the medical image requires a lot of effort by professionals, which is also a subjective task. Therefore, developing an advanced segmentation method is an essential demand. We propose an end-to-end segmentation method for medical images, which mimics physicians delineating a region of interest (ROI) on the medical image in a multi-step manner. This multi-step operation improves the performance from a coarse result to a fine result progressively. In this paper, the segmentation process is formulated as a Markov decision process and solved by a deep reinforcement learning (DRL) algorithm, which trains an agent for segmenting ROI in images. The agent performs a serial action to delineate the ROI. We define the action as a set of continuous parameters. Then, we adopted a DRL algorithm called deep deterministic policy gradient to learn the segmentation model in continuous action space. The experimental result shows that the proposed method has 7.24\% improved to the state-of-the-art method on three prostate MR data sets and has 3.52\% improved on one retinal fundus image data set.}
}

@article{yuTumorSegmentationBreast2021,
  title = {Tumor {{Segmentation}} in {{Breast Ultrasound Image}} by {{Means}} of {{Res Path Combined}} with {{Dense Connection Neural Network}}},
  author = {Yu, Kailuo and Chen, Sheng and Chen, Yanghuai},
  date = {2021-08-28},
  journaltitle = {Diagnostics (Basel, Switzerland)},
  shortjournal = {Diagnostics (Basel)},
  volume = {11},
  number = {9},
  eprint = {34573907},
  eprinttype = {pmid},
  pages = {1565},
  issn = {2075-4418},
  doi = {10.3390/diagnostics11091565},
  abstract = {Over the past few years, researchers have demonstrated the possibilities to use the Computer-Aided Diagnosis (CAD) to provide a preliminary diagnosis. Recently, it is also becoming increasingly common for doctors and computer practitioners to collaborate on developing CAD. Since the early diagnosis of breast cancer is the most critical step, a precise segmentation of breast tumor with accurate edge and shape is vital for accurate diagnoses and reduction in the patients' pain. In view of the deficient accuracy of existing method, we proposed a novel method based on U-Net to improve the tumor segmentation accuracy in breast ultrasound images. First, Res Path was introduced into the U-Net to reduce the difference between the feature maps of the encoder and decoder. Then, a new connection, dense block from the input of the feature maps in the encoding-to-decoding section, was added to reduce the feature information loss and alleviate the vanishing gradient problem. A breast ultrasound database, which contains 538 tumor images, from Xinhua Hospital in Shanghai and marked by two professional doctors was used to train and test models. We, using ten-fold cross-validation method, compared the U-Net, U-Net with Res Path, and the proposed method to verify the improvements. The results demonstrated an overall improvement by the proposed approach when compared with the other in terms of true-positive rate, false-positive rate, Hausdorff distance indices, Jaccard similarity, and Dice coefficients.},
  langid = {english},
  pmcid = {PMC8467674},
  keywords = {breast ultrasound,Res Path,tumor segmentation}
}
